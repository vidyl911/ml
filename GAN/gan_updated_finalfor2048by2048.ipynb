{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gan_updated_finalfor2048by2048.ipynb","private_outputs":true,"provenance":[{"file_id":"1_BV039Mp7CBV1yr5ZngMdknS1_jo9nto","timestamp":1607199267178},{"file_id":"1H57_0CaNfkw5Vlct5L34-Sa5569wSoFu","timestamp":1607198252626},{"file_id":"1oqeBkiEQnVnyA4wKEERAfUAtZL8KJaKQ","timestamp":1607197717803},{"file_id":"1ycA1LjIEyq-DmNj4KulIKm5kaaSG8oEJ","timestamp":1607197683474},{"file_id":"1dAO_MCVxcmbghvWm2qnSfr_ysXVdqFGV","timestamp":1607197215775},{"file_id":"1HayRkT3OlQVhQbSoFlW1QkjH5SN1CNY2","timestamp":1607194084223},{"file_id":"1zteYbnseFcXeU7wLGip2ZuUTxRuI-7cK","timestamp":1607183028134},{"file_id":"1MNPU6A5rsvHGsLdbSCeT0EtcJ3hANjaK","timestamp":1589211923604}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"1_vWXEaF_2L2"},"source":["\n","# Deep Convolutional GANs\n","encoded_image=[]\n","# Importing the libraries\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","from torch.autograd import Variable\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","!rm -rf \"sample_data\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ozGhOJtZFFo"},"source":["ngpu=4\n","import os\n","number_of_persons=1\n","encodedir='./encodedimage/'\n","if not os.path.exists(encodedir):\n","    os.makedirs(encodedir)\n","    print(\"Directory \" , encodedir ,  \" Created \")\n","else:    \n","    print(\"Directory \" , encodedir ,  \" already exists\")\n","for n_person_directory in range(1,number_of_persons+1):\n","  dirName1 = './images/'+'test'+str(n_person_directory)+'/person'+str(n_person_directory)+'/'\n","\n","  # Create target Directory if don't exist\n","  if not os.path.exists(dirName1):\n","      os.makedirs(dirName1)\n","      print(\"Directory \" , dirName1 ,  \" Created \")\n","  else:    \n","      print(\"Directory \" , dirName1 ,  \" already exists\")\n","\n","\n","  dirName='./results_of_person'+str(n_person_directory)+'/'\n","  # Create target Directory if don't exist\n","  if not os.path.exists(dirName):\n","      os.makedirs(dirName)\n","      print(\"Directory \" , dirName ,  \" Created \")\n","  else:    \n","      print(\"Directory \" , dirName ,  \" already exists\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"knzxWRoixQAB"},"source":["for n_person_loop in range(1,number_of_persons+1):\n","  random.seed(n_person_loop)\n","  torch.manual_seed(n_person_loop)\n","  dirName='./results_of_person'+str(n_person_loop)+'/'\n","  # Setting some hyperparameters\n","  batchSize = 1 # We set the size of the batch. batchSize=1 means we will provide only one image of one person\n","  imageSize = 64 #It is actually not the size, I have multiplied it with the factor of 8 to make it 512x512\n","  \n","  # Creating the transformations\n","  TRANSFORM_IMG = transforms.Compose([\n","      transforms.Resize(imageSize*32),\n","      transforms.CenterCrop(imageSize*32),\n","      transforms.ToTensor(),\n","      transforms.Normalize(mean=[0.5, 0.5, 0.5],\n","                          std=[0.5, 0.5, 0.5] )\n","      ])\n","  TRAIN_DATA_PATH = './images/test'+str(n_person_loop)+'/'\n","\n","\n","  # Loading the dataset\n","  dataset = dset.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG) # Applying transformation on each image.\n","  dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchSize, shuffle = False, num_workers = 0) # We use dataLoader to get the images of the training set batch by batch.\n","  \n","\n","  # Decide which device we want to run on\n","  device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n","\n","  # Plot some training images\n","  real_batch = next(iter(dataloader))\n","  plt.figure(figsize=(32,32))\n","  plt.axis(\"off\")\n","  plt.title(\"Training Images\")\n","  plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:imageSize*32], padding=2, normalize=True).cpu(),(1,2,0)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LRGt7bHF-eqQ"},"source":["\n","\n","\n","for n_person_loop in range(1,number_of_persons+1):\n","  random.seed(n_person_loop)\n","  torch.manual_seed(n_person_loop)\n","  dirName='./results_of_person'+str(n_person_loop)+'/'\n","  # Setting some hyperparameters\n","  batchSize = 1 # We set the size of the batch. batchSize=1 means we will provide only one image of one person\n","  imageSize =64 #It is actually not the size, I have multiplied it with the factor of 8 to make it 512x512\n","  \n","  # Creating the transformations\n","  TRANSFORM_IMG = transforms.Compose([\n","      transforms.Resize(imageSize*32),\n","      transforms.CenterCrop(imageSize*32),\n","      transforms.ToTensor(),\n","      transforms.Normalize(mean=[0.5, 0.5, 0.5],\n","                          std=[0.5, 0.5, 0.5] )\n","      ])\n","  TRAIN_DATA_PATH = './images/test'+str(n_person_loop)+'/'\n","\n","\n","  # Loading the dataset\n","  dataset = dset.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG) # Applying transformation on each image.\n","  dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchSize, shuffle = False, num_workers = 0) # We use dataLoader to get the images of the training set batch by batch.\n","  \n","\n","  # Decide which device we want to run on\n","  device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n","  # device = torch.device(\"cpu\") #If you strictly want to use the cpu\n","  \n","\n","  # Plot some training images\n","  real_batch = next(iter(dataloader))\n","  plt.figure(figsize=(32,32))\n","  plt.axis(\"off\")\n","  plt.title(\"Training Images\")\n","  plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:imageSize*32], padding=2, normalize=True).cpu(),(1,2,0)))\n","\n","\n","  def weights_init(m):\n","      classname = m.__class__.__name__\n","      if classname.find('Conv') != -1:\n","          m.weight.data.normal_(0.0, 0.02)\n","      elif classname.find('BatchNorm') != -1:\n","          m.weight.data.normal_(1.0, 0.02)\n","          m.bias.data.fill_(0)\n","\n","\n","  # Defining the generator\n","\n","  class G(nn.Module): # We introduce a class to define the generator.\n","\n","      def __init__(self,ngpu): # We introduce the __init__() function that will define the architecture of the generator.\n","          super(G, self).__init__() # We inherit from the nn.Module tools.\n","          self.ngpu=ngpu\n","          \n","          self.main = nn.Sequential( # We create a meta module of a neural network that will contain a sequence of modules (convolutions, full connections, etc.).\n","              nn.ConvTranspose2d(100, imageSize*256, 4, 1, 0, bias = False), # We start with an inversed convolution.\n","              nn.BatchNorm2d(imageSize*256), # We normalize all the features along the dimension of the batch.\n","              nn.ReLU(True), # We apply a ReLU rectification to break the linearity.              \n","\n","              nn.ConvTranspose2d(imageSize*256, imageSize*128, 4, 2, 1, bias = False), # We start with an inversed convolution.\n","              nn.BatchNorm2d(imageSize*128), # We normalize all the features along the dimension of the batch.\n","              nn.ReLU(True), # We apply a ReLU rectification to break the linearity.\n","\n","              nn.ConvTranspose2d(imageSize*128, imageSize*64, 4, 2, 1, bias = False), # We start with an inversed convolution.\n","              nn.BatchNorm2d(imageSize*64), # We normalize all the features along the dimension of the batch.\n","              nn.ReLU(True), # We apply a ReLU rectification to break the linearity.\n","\n","              nn.ConvTranspose2d(imageSize*64, imageSize*32, 4, 2, 1, bias = False), # We start with an inversed convolution.\n","              nn.BatchNorm2d(imageSize*32), # We normalize all the features along the dimension of the batch.\n","              nn.ReLU(True), # We apply a ReLU rectification to break the linearity.\n","\n","              nn.ConvTranspose2d(imageSize*32, imageSize*16, 4, 2, 1, bias = False), # We start with an inversed convolution.\n","              nn.BatchNorm2d(imageSize*16), # We normalize all the features along the dimension of the batch.\n","              nn.ReLU(True), # We apply a ReLU rectification to break the linearity.\n","              nn.ConvTranspose2d(imageSize*16, imageSize*8, 4, 2, 1, bias = False), # We add another inversed convolution.\n","              nn.BatchNorm2d(imageSize*8), # We normalize again.\n","              nn.ReLU(True), # We apply another ReLU.\n","              nn.ConvTranspose2d(imageSize*8, imageSize*4, 4, 2, 1, bias = False), # We add another inversed convolution.\n","              nn.BatchNorm2d(imageSize*4), # We normalize again.\n","              nn.ReLU(True), # We apply another ReLU.\n","              nn.ConvTranspose2d(imageSize*4, imageSize*2, 4, 2, 1, bias = False), # We add another inversed convolution.\n","              nn.BatchNorm2d(imageSize*2), # We normalize again.\n","              nn.ReLU(True), # We apply another ReLU.\n","              nn.ConvTranspose2d(imageSize*2,imageSize, 4, 2, 1, bias = False), # We add another inversed convolution.\n","              nn.BatchNorm2d(imageSize), # We normalize again.\n","              nn.ReLU(True), # We apply another ReLU.\n","              nn.ConvTranspose2d(imageSize, 3, 4, 2, 1, bias = False), # We add another inversed convolution.\n","              nn.Tanh() # We apply a Tanh rectification to break the linearity and stay between -1 and +1.\n","              \n","              )\n","      \n","      def forward(self, input): # We define the forward function that takes as argument an input that will be fed to the neural network, and that will return the output containing the generated images.\n","          output = self.main(input) # We forward propagate the signal through the whole neural network of the generator defined by self.main.\n","          global encoded_image\n","          encoded_image=torch.atanh(output)\n","          \n","          return output # We return the output containing the generated images.\n","      \n","\n","  \n","  # Create the generator\n","  netG = G(ngpu).to(device)\n","\n","  # Handle multi-gpu if desired\n","  if (device.type == 'cuda') and (ngpu > 1):\n","      netG = nn.DataParallel(netG, list(range(ngpu)))\n","  # Apply the weights_init function to randomly initialize all weights\n","  #  to mean=0, stdev=0.2.\n","  netG.apply(weights_init)\n","\n","  # Print the model\n","  #print(netG)\n","\n","  # Defining the discriminator\n","\n","  class D(nn.Module): # We introduce a class to define the discriminator.\n","\n","      def __init__(self,ngpu): # We introduce the __init__() function that will define the architecture of the discriminator.\n","          super(D, self).__init__() # We inherit from the nn.Module tools.\n","          self.ngpu=ngpu\n","          self.main = nn.Sequential( # We create a meta module of a neural network that will contain a sequence of modules (convolutions, full connections, etc.).\n","              nn.Conv2d(3, imageSize, 4, 2, 1, bias = False), # We start with a convolution.\n","              nn.LeakyReLU(0.2, inplace = True), # We apply a LeakyReLU.\n","              nn.Conv2d(imageSize, imageSize*2, 4, 2, 1, bias = False), # We add another convolution.\n","              nn.BatchNorm2d(imageSize*2), # We normalize all the features along the dimension of the batch.\n","              nn.LeakyReLU(0.2, inplace = True), # We apply another LeakyReLU.\n","              nn.Conv2d(imageSize*2, imageSize*4, 4, 2, 1, bias = False), # We add another convolution.\n","              nn.BatchNorm2d(imageSize*4), # We normalize again.\n","              nn.LeakyReLU(0.2, inplace = True), # We apply another LeakyReLU.\n","              nn.Conv2d(imageSize*4, imageSize*8, 4, 2, 1, bias = False), # We add another convolution.\n","              nn.BatchNorm2d(imageSize*8), # We normalize again.\n","              nn.LeakyReLU(0.2, inplace = True), # We apply another LeakyReLU.\n","\n","              nn.Conv2d(imageSize*8, imageSize*16, 4, 2, 1, bias = False), # We add another convolution.\n","              nn.BatchNorm2d(imageSize*16), # We normalize again.  #16\n","              nn.LeakyReLU(0.2, inplace = True), # We apply another LeakyReLU.\n","              nn.Conv2d(imageSize*16, imageSize*32, 4, 2, 1, bias = False), # We add another convolution.\n","              nn.BatchNorm2d(imageSize*32), # We normalize again.  #16\n","              nn.LeakyReLU(0.2, inplace = True), # We apply another LeakyReLU.  \n","\n","              nn.Conv2d(imageSize*32, imageSize*64, 4, 2, 1, bias = False), # We add another convolution.\n","              nn.BatchNorm2d(imageSize*64), # We normalize again.  #16\n","              nn.LeakyReLU(0.2, inplace = True), # We apply another LeakyReLU.                 \n","\n","              nn.Conv2d(imageSize*64, imageSize*128, 4, 2, 1, bias = False), # We add another convolution.\n","              nn.BatchNorm2d(imageSize*128), # We normalize again.  #16\n","              nn.LeakyReLU(0.2, inplace = True), # We apply another LeakyReLU.  \n","\n","\n","\n","              nn.Conv2d(imageSize*128, imageSize*256, 4, 2, 1, bias = False), # We add another convolution.\n","              nn.BatchNorm2d(imageSize*256), # We normalize again.  #16\n","              nn.LeakyReLU(0.2, inplace = True), # We apply another LeakyReLU.  \n","\n","\n","              nn.Conv2d(imageSize*256, 1, 4, 1, 0, bias = False), # We add another convolution.  #16\n","              nn.Sigmoid() # We apply a Sigmoid rectification to break the linearity and stay between 0 and 1.\n","              \n","              )\n","\n","      def forward(self, input): # We define the forward function that takes as argument an input that will be fed to the neural network, and that will return the output which will be a value between 0 and 1.\n","          output = self.main(input) # We forward propagate the signal through the whole neural network of the discriminator defined by self.main.\n","          return output.view(-1) # We return the output which will be a value between 0 and 1.\n","\n","  # Create the Discriminator\n","  netD = D(ngpu).to(device)\n","  if (device.type == 'cuda') and (ngpu > 1):\n","      netD = nn.DataParallel(netD, list(range(ngpu)))\n","\n","  # Apply the weights_init function to randomly initialize all weights\n","  #  to mean=0, stdev=0.2.\n","  netD.apply(weights_init)\n","\n","  # Print the model\n","  #print(netD)\n","\n","  # Training the DCGANs\n","\n","  criterion = nn.BCELoss() # We create a criterion object that will measure the error between the prediction and the target.\n","  optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999)) # We create the optimizer object of the discriminator.\n","  optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999)) # We create the optimizer object of the generator.\n","  \n","  G_losses=[]\n","  D_losses=[]\n","  n_epochs=1\n","  for epoch in range(1,n_epochs+1): # We iterate over number of epochs.\n","\n","      for i, data in enumerate(dataloader, 0): # We iterate over the images of the dataset.\n","          \n","          # 1st Step: Updating the weights of the neural network of the discriminator\n","\n","          netD.zero_grad() # We initialize to 0 the gradients of the discriminator with respect to the weights.\n","          \n","          # Training the discriminator with a real image of the dataset\n","          real = data[0].to(device) # We get a real image of the dataset which will be used to train the discriminator.\n","          input = Variable(real) # We wrap it in a variable.\n","          target = Variable(torch.ones(input.size()[0]).to(device)) # We get the target.\n","          output = netD(input) # We forward propagate this real image into the neural network of the discriminator to get the prediction (a value between 0 and 1).\n","          errD_real = criterion(output, target) # We compute the loss between the predictions (output) and the target (equal to 1).\n","          \n","          # Training the discriminator with a fake image generated by the generator\n","          noise = Variable(torch.randn(input.size()[0], 100, 1, 1).to(device)) # We make a random input vector (noise) of the generator.\n","          fake = netG(noise) # We forward propagate this random input vector into the neural network of the generator to get some fake generated images.\n","          target = Variable(torch.zeros(input.size()[0]).to(device)) # We get the target.\n","          output = netD(fake.detach()) # We forward propagate the fake generated images into the neural network of the discriminator to get the prediction (a value between 0 and 1).\n","          errD_fake = criterion(output, target) # We compute the loss between the prediction (output) and the target (equal to 0).\n","\n","          # Backpropagating the total error\n","          errD = errD_real + errD_fake # We compute the total error of the discriminator.\n","          errD.backward() # We backpropagate the loss error by computing the gradients of the total error with respect to the weights of the discriminator.\n","          optimizerD.step() # We apply the optimizer to update the weights according to how much they are responsible for the loss error of the discriminator.\n","\n","          # 2nd Step: Updating the weights of the neural network of the generator\n","\n","          netG.zero_grad() # We initialize to 0 the gradients of the generator with respect to the weights.\n","          target = Variable(torch.ones(input.size()[0]).to(device)) # We get the target.\n","          output = netD(fake) # We forward propagate the fake generated images into the neural network of the discriminator to get the prediction (a value between 0 and 1).\n","          errG = criterion(output, target) # We compute the loss between the prediction (output between 0 and 1) and the target (equal to 1).\n","          errG.backward() # We backpropagate the loss error by computing the gradients of the total error with respect to the weights of the generator.\n","          optimizerG.step() # We apply the optimizer to update the weights according to how much they are responsible for the loss error of the generator.\n","          \n","          # 3rd Step: Printing the losses and saving the real images and the generated images of the minibatch every 100 steps\n","\n","          #print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, n_epochs, i, len(dataloader), errD.data, errG.data)) # We print les losses of the discriminator (Loss_D) and the generator (Loss_G).\n","          G_losses.append(errG.item())\n","          D_losses.append(errD.item())\n","          vutils.save_image(real, '%s/real_samples.png' % dirName, normalize = True) # We save the real images of the minibatch.\n","          fake = netG(noise) # We get our fake generated images.\n","          vutils.save_image(fake.data, '%s/fake_samples_epoch_%04d.png' % (dirName, epoch), normalize = True) # We also save the fake generated images of the minibatch.\n","\n","  plt.figure(figsize=(10,5))\n","  plt.title(\"Generator and Discriminator Loss During Training\")\n","  plt.plot(G_losses,label=\"G\")\n","  plt.plot(D_losses,label=\"D\")\n","  plt.xlabel(\"iterations\")\n","  plt.ylabel(\"Loss\")\n","  plt.legend()\n","  plt.show()          \n","  dir2=\"saved_models/fake_images\"\n","  dir3=\"saved_models/fake_images/fake_images_person\"\n","  if not os.path.exists(dir2):\n","      os.makedirs(dir2)\n","      print(\"Directory \" , dir2 ,  \" Created \")\n","  else:    \n","      print(\"Directory \" , dir2 ,  \" already exists\")\n","\n","  dir1=\"models/pytorch\"\n","  if not os.path.exists(dir1):\n","      os.makedirs(dir1)\n","      print(\"Directory \" , dir1 ,  \" Created \")\n","  else:    \n","      print(\"Directory \" , dir1 ,  \" already exists\")\n","  \n","  pathG=\"models/pytorch/G.pth_person\"+str(n_person_loop)\n","  \n","  torch.save(netG, pathG)\n","\n","  pathG_weights=\"models/pytorch/G.h5_person\"+str(n_person_loop)\n","\n","  torch.save(netG.state_dict(),pathG_weights )\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z65fbNUIgxgE"},"source":["\n","vutils.save_image(encoded_image, '%s/encoded.png' % encodedir, normalize = True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BeBdWyJvuPhA"},"source":["\n","%pylab inline\n","print (\"\\n\\n\\nEncoded image below\")\n","imge=mpimg.imread(\"./encodedimage/encoded.png\")\n","imgplote = plt.imshow(imge)\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDnwx0YsVa-_"},"source":["for n_person_test in range(1,number_of_persons+1):\n","  batchSize=1\n","  random.seed(n_person_loop)\n","  torch.manual_seed(n_person_test)\n","  dir3_test=\"saved_models/fake_images/fake_images_person\"\n","  pathG_test=\"models/pytorch/G.pth_person\"+str(n_person_test)\n","  \n","\n","  netGG = torch.load(pathG_test)\n","  netGG.eval()\n","  \n","  noi = Variable(torch.randn(batchSize, 100, 1, 1).to(device)) # We make a random input vector (noise) of the generator.\n","  fa = netGG(noi)\n","\n","  vutils.save_image(fa.detach(), dir3_test+str(n_person_test)+\".png\", normalize=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nebc2_OrqmlJ"},"source":["n_persons=1\n","for n_person_test_weight in range(1,n_persons+1):\n","  random.seed(n_person_test_weight)\n","  torch.manual_seed(n_person_test_weight)\n","  dir4=\"saved_models/fake_images_by_weights\"\n","  dir5=\"saved_models/fake_images_by_weights/fake_images_person\"\n","  if not os.path.exists(dir4):\n","      os.makedirs(dir4)\n","      print(\"Directory \" , dir4 ,  \" Created \")\n","  else:    \n","      print(\"Directory \" , dir4 ,  \" already exists\")\n","\n","  pathG_weights=\"models/pytorch/G.h5_person\"+str(n_person_test_weight)\n","  \n","  netG.load_state_dict(torch.load(pathG_weights))\n","  netG.eval()\n"," \n","\n","\n","\n","  noiw = Variable(torch.randn(16, 100, 1, 1).to(device)) # We make a random input vector (noise) of the generator.\n","  faw= netG(noi)\n","\n","  vutils.save_image(fa.detach(), dir5+str(n_person_test_weight)+\".png\", normalize=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"foSdhck4bs7M"},"source":["# !rm -rf \"saved_models\"\n","# !rm -rf \"models\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FyVQVCeUl3IB"},"source":[""]},{"cell_type":"code","metadata":{"id":"Js65bB2flU8s"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kddWTwgkUMFG"},"source":[""],"execution_count":null,"outputs":[]}]}